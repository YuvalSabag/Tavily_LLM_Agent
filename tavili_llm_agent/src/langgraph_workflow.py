import logging
import tiktoken
from langchain import requests
from langchain.adapters import openai

from src.integration_nodes import TavilyAPI, OpenAINode, clean_content

# Setup logging
logger = logging.getLogger(__name__)


# Constants for Token Management
MAX_TOKENS = 3000  # Reserve tokens for query and prompts

def count_tokens(text):
    """
    Calculates the exact number of tokens using OpenAI's tokenizer.
    """
    tokenizer = tiktoken.encoding_for_model("gpt-4")
    return len(tokenizer.encode(text))

def fetch_search_results(tavily_api, query):
    """
    Fetch search results from Tavily API.

    Args:
        tavily_api (TavilyAPI): Instance of TavilyAPI.
        query (str): The user's search query.

    Returns:
        dict: The JSON response from Tavily API or None if an error occurred.

    """
    if not query.strip():
        return {"error": "Query is empty. Provide a valid search query."}

    try:
        results = tavily_api.search(query)
        if not results or "results" not in results:
            return {"error": "No results found from Tavily API."}
        return results
    except requests.exceptions.RequestException as e:
        return {"error": f"Error fetching results: {str(e)}"}

def process_search_results(search_results, max_results=3):
    """
    Process the search results and extract relevant information efficiently.

    Args:
        search_results (dict): The JSON response from Tavily API.
        max_results (int): The maximum number of results to process.

    Returns:
        str: A concatenated string of search results' content or an error message.
    """
    # Check if search_results is valid
    if not search_results or not isinstance(search_results, dict):
        return {"error": "Invalid search results format. Expected a dictionary."}

    results = search_results.get("results", [])
    if not results:
        return {"error": "No valid search results found."}

    try:
        context = []
        current_tokens = 0

        # Lazy processing of search results
        def process_result(result):
            if not isinstance(result, dict):
                return None  # Skip invalid result formats
            content = result.get("content", "").strip()
            if not content:
                return None  # Skip empty content
            tokens = count_tokens(content)
            return {"content": content, "tokens": tokens}

        # Process results efficiently
        for result in results:
            processed = process_result(result)
            if not processed:
                continue  # Skip invalid or empty results

            if current_tokens + processed["tokens"] > MAX_TOKENS:
                break  # Stop if token limit is exceeded

            context.append(processed["content"])
            current_tokens += processed["tokens"]

            if len(context) >= max_results:
                break  # Stop if maximum results are processed

        if not context:
            return {"error": "All processed results are empty or invalid."}

        return "\n\n".join(context)

    except Exception as e:
        logger.error(f"Error processing search results: {str(e)}")
        return {"error": f"Unexpected error while processing search results: {str(e)}"}


def generate_response(openai_node, context, query):
    """
    Generate a response based on the search context and query using OpenAI GPT-4.

    Args:
        openai_node (OpenAINode): Instance of OpenAINode.
        context (str): The retrieved search results.
        query (str): The user's search query.

    Returns:
        str: The generated response or an error message.
    """
    if not context.strip() or not query.strip():
        return {"error": "Context or query is empty. Cannot generate a response."}

    try:
        response = openai_node.generate_response(context, query)
        if not response:
            return {"error": "No response generated by OpenAI."}
        return response
    except openai.error.OpenAIError as e:
        return {"error": f"OpenAI error: {str(e)}"}
    except Exception as e:
        return {"error": f"Unexpected error generating response: {str(e)}"}


def ai_workflow(user_query):
    """
    Main workflow that fetches search results and generates a response.

    Args:
        user_query (str): The user's search query.

    Returns:
        dict: Contains search results and the GPT-4 response.
    """
    # Validate user query
    if not user_query.strip():
        logger.error("User query is empty. Please provide a valid query.")
        return {"error": "Invalid user query. The query cannot be empty."}

    # Initialize Tavily API and OpenAI node
    tavily_api = TavilyAPI()
    openai_node = OpenAINode()

    # Fetch search results
    logger.info("Fetching search results from Tavily API...")
    search_results = fetch_search_results(tavily_api, user_query)

    if not search_results or "error" in search_results:
        return {
            "error": search_results.get("error", "No results from Tavily API.")
        }

    # Process search results
    logger.info("Processing search results...")
    context = process_search_results(search_results)

    if not context or (isinstance(context, dict) and "error" in context):
        return {
            "search_results": search_results,
            "error": context.get("error", "No valid context for response generation.")
        }

    # Generate GPT-4 response
    logger.info("Generating response with OpenAI...")
    gpt_response = openai_node.generate_response(context, user_query)

    if not gpt_response:
        return {
            "search_results": search_results,
            "error": "Failed to generate a response using GPT-4. Please refine your query and try again."
        }

    logger.info("Workflow complete. Returning results...")
    return {
        "search_results": search_results,
        "gpt_response": gpt_response,
        "relevant_links": [result.get("url") for result in search_results.get("results", []) if result.get("url")]
    }
